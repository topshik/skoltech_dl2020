{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "gFe273vKFgF-"
   },
   "source": [
    "# Homework 2, *part 2*\n",
    "### (60 points total)\n",
    "\n",
    "In this part, you will build a convolutional neural network (CNN) to solve (yet another) image classification problem: the Tiny ImageNet dataset (200 classes, 100K training images, 10K validation images). Try to achieve as high accuracy as possible.\n",
    "\n",
    "**Unlike part 1**, you are now free to use the full power of PyTorch and its subpackages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hKjuxXAgFgGA"
   },
   "source": [
    "## Deliverables\n",
    "\n",
    "* This file.\n",
    "* A \"checkpoint file\" `\"checkpoint.pth\"` that contains your CNN's weights (you get them from `model.state_dict()`). Obtain it with `torch.save(..., \"checkpoint.pth\")`. When grading, we will load it to evaluate your accuracy.\n",
    "\n",
    "**Should you decide to put your `\"checkpoint.pth\"` on Google Drive, update (edit) the following cell with the link to it:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O4kOWlcXFgGD"
   },
   "source": [
    "### [Dear TAs, I've put my \"checkpoint.pth\" on Google Drive, download it here](https://drive.google.com/open?id=18dh9YnzftE950KKDyXAwGA7cS0XLHsNt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-S-WyYK8FgGF"
   },
   "source": [
    "## Grading\n",
    "\n",
    "* 9 points for reproducible training code and a filled report below.\n",
    "* 11 points for building a network that gets above 25% accuracy.\n",
    "* 4 points for using an **interactive** (please don't reinvent the wheel with `plt.plot`) tool for viewing progress, for example Tensorboard ([with this library](https://github.com/lanpa/tensorboardX) and [an extra hack for Colab](https://stackoverflow.com/a/57791702)). In this notebook, insert screenshots of accuracy and loss plots (training and validation) over iterations/epochs/time.\n",
    "* 6 points for beating each of these accuracy milestones on the private **test** set:\n",
    "  * 30%\n",
    "  * 34%\n",
    "  * 38%\n",
    "  * 42%\n",
    "  * 46%\n",
    "  * 50%\n",
    "  \n",
    "*Private test set* means that you won't be able to evaluate your model on it. Rather, after you submit code and checkpoint, we will load your model and evaluate it on that test set ourselves, reporting your accuracy in a comment to the grade.\n",
    "\n",
    "Note that there is an important formatting requirement, see below near \"`DO_TRAIN = True`\".\n",
    "\n",
    "## Restrictions\n",
    "\n",
    "* No pretrained networks.\n",
    "* Don't enlarge images (e.g. don't resize them to $224 \\times 224$ or $256 \\times 256$).\n",
    "\n",
    "## Tips\n",
    "\n",
    "* **One change at a time**: never test several new things at once (unless you are super confident). Train a model, introduce one change, train again.\n",
    "* Google a lot: try to reinvent as few wheels as possible (unlike in part 1 of this assignment).\n",
    "* Use GPU.\n",
    "* Use regularization: L2, batch normalization, dropout, data augmentation...\n",
    "* Pay much attention to accuracy and loss graphs (e.g. in Tensorboard). Track failures early, stop bad experiments early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m2qxvLGdFgGH"
   },
   "outputs": [],
   "source": [
    "# Detect if we are in Google Colaboratory\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "from pathlib import Path\n",
    "# Determine the locations of auxiliary libraries and datasets.\n",
    "# `AUX_DATA_ROOT` is where 'notmnist.py', 'animation.py' and 'tiny-imagenet-2020.zip' are.\n",
    "if IN_COLAB:\n",
    "    google.colab.drive.mount(\"/content/drive\")\n",
    "    \n",
    "    # Change this if you created the shortcut in a different location\n",
    "    AUX_DATA_ROOT = Path(\"/content/drive/My Drive/Deep Learning 2020 -- Home Assignment 2\")\n",
    "    \n",
    "    assert AUX_DATA_ROOT.is_dir(), \"Have you forgot to 'Add a shortcut to Drive'?\"\n",
    "else:\n",
    "    AUX_DATA_ROOT = Path(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G_6veP_5FgGS"
   },
   "source": [
    "The below cell puts training and validation images in `./tiny-imagenet-200/train` and `./tiny-imagenet-200/val`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "njk50aDoFgGT"
   },
   "outputs": [],
   "source": [
    "# Extract the dataset into the current directory\n",
    "if not Path(\"tiny-imagenet-200/train/class_000/00000.jpg\").is_file():\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(AUX_DATA_ROOT / 'tiny-imagenet-2020.zip', 'r') as archive:\n",
    "        archive.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P1mtHCQcFgGb"
   },
   "source": [
    "**You are required** to format your notebook cells so that `Run All` on a fresh notebook:\n",
    "* trains your model from scratch, if `DO_TRAIN is True`;\n",
    "* loads your trained model from `\"./checkpoint.pth\"`, then **computes** and prints its validation accuracy, if `DO_TRAIN is False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QvH36LxFgGc"
   },
   "outputs": [],
   "source": [
    "DO_TRAIN = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rgg4D0zSFgGi"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from IPython import display\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AFqnb1-EFgGj",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.5.0\n",
      "Using GPU\n",
      "100000 training images\n",
      "10000 validation images\n",
      "Train/test dataloaders have 196 and 20 batches\n"
     ]
    }
   ],
   "source": [
    "# set up device\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "print(\"torch\", torch.__version__)\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    dtype = torch.FloatTensor\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Not using GPU\")\n",
    "    \n",
    "# load data\n",
    "transform = {\n",
    "    'train': transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(30),\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05, hue=0.05),\n",
    "            transforms.ToTensor(),\n",
    "        ]),\n",
    "    'test': transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "}\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder('tiny-imagenet-200/train', transform=transform['train'])\n",
    "test_dataset  = torchvision.datasets.ImageFolder('tiny-imagenet-200/val', transform=transform['test'])\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "print(f'{len(train_dataset)} training images')\n",
    "print(f'{len( test_dataset)} validation images')\n",
    "image, label = train_dataset[50]\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "NUM_WORKERS = 10\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, \n",
    "                              shuffle=True, pin_memory=True)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, \n",
    "                            shuffle=False, pin_memory=True)\n",
    "\n",
    "print(f\"Train/test dataloaders have {len(train_dataloader)} and {len(test_dataloader)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TonyNet(torch.nn.Module):\n",
    "    def __init__(self, vgg):\n",
    "        super(TonyNet, self).__init__()\n",
    "        features = []\n",
    "        for i, module in enumerate(vgg.features):\n",
    "            if i <= 23:\n",
    "                features.append(module)\n",
    "        self.features = torch.nn.Sequential(*features)\n",
    "        self.avg_pool = torch.nn.AdaptiveAvgPool2d(output_size=(7, 7))\n",
    "        self.classifier = torch.nn.Sequential(torch.nn.Linear(7 * 7 * 512, 4096),\n",
    "                                              torch.nn.ReLU(inplace=True),\n",
    "                                              torch.nn.Dropout(),\n",
    "                                              torch.nn.Linear(4096, 4096),\n",
    "                                              torch.nn.ReLU(inplace=True),\n",
    "                                              torch.nn.Dropout(),\n",
    "                                              torch.nn.Linear(4096, 200))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        feats = self.features(x)\n",
    "        pooled = self.avg_pool(feats)\n",
    "        fltnd = torch.nn.Flatten()(pooled)\n",
    "        return self.classifier(fltnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, val_dataloader, opt, criterion, n_epochs=100, chckpnt_path='./checkpoint.pth'):\n",
    "    date = datetime.datetime.now().strftime(\"%b-%d-%Y-%H:%M:%S\")\n",
    "    writer_train = SummaryWriter(f'runs/{date}/train')\n",
    "    writer_test = SummaryWriter(f'runs/{date}/test')\n",
    "    scheduler = ReduceLROnPlateau(opt, factor=0.5)\n",
    "    best_acc = 0\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        model.train()\n",
    "        correct, total = 0, 0\n",
    "        for j, (images, labels) in enumerate(tqdm(train_dataloader)):\n",
    "            probs = model(images.to(device))\n",
    "            with torch.no_grad():\n",
    "                labels = labels.to(device)\n",
    "                predictions = probs.max(1)[1]\n",
    "\n",
    "                total += len(labels)\n",
    "                correct += (predictions == labels).sum().item()\n",
    "\n",
    "            loss = criterion(probs, labels)\n",
    "            writer_train.add_scalar('Loss', loss, i * len(train_dataloader) + j)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_acc = correct / total\n",
    "        writer_train.add_scalar('Accuracy', train_acc, i)\n",
    "\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        for j, (images, labels) in enumerate(tqdm(val_dataloader)):\n",
    "            with torch.no_grad():\n",
    "                probs = model(images.to(device))\n",
    "                labels = labels.to(device)\n",
    "                predictions = probs.max(1)[1]\n",
    "                total += len(labels)\n",
    "                correct += (predictions == labels).sum().item()\n",
    "                val_loss = criterion(probs, labels)\n",
    "#                 scheduler.step(test_loss)\n",
    "                writer_test.add_scalar('Loss', val_loss, \n",
    "                                       (i * len(val_dataloader) + j) * len(train_dataloader) / len(val_dataloader))\n",
    "        val_acc = correct / total\n",
    "        writer_test.add_scalar('Accuracy', val_acc, i)\n",
    "        display.clear_output(True)\n",
    "        print(f'Epoch number: {i}')\n",
    "        print(f'Train accuracy: {train_acc}')\n",
    "        print(f'Validation accuracy: {val_acc}')\n",
    "        if val_acc > best_acc:\n",
    "            torch.save(model.state_dict(), chckpnt_path)\n",
    "            best_acc = val_acc\n",
    "        \n",
    "    return train_acc, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J9n7DyGcFgGq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 20/196 [01:07<01:53,  1.55it/s] "
     ]
    }
   ],
   "source": [
    "vgg16 = torchvision.models.vgg16()\n",
    "if DO_TRAIN:\n",
    "    # Your code here (train your model)\n",
    "    # etc.\n",
    "    tony_net = TonyNet(vgg16)\n",
    "    tony_net.to(device)\n",
    "    learning_rate = 3e-4\n",
    "    optimizer = torch.optim.Adam(tony_net.parameters(), lr=learning_rate)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    train_acc, test_acc = train(tony_net, train_dataloader, test_dataloader, optimizer, criterion, n_epochs=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I swear the code above works :). It just didn't save the resulting accuracy, but the model is saved and tested below, giving the neede results. The training took ~6 hours, so I didn't rerun it just to avoid this error message, which doesn't even spoil the workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OHFdDYv8FgGx"
   },
   "source": [
    "## Load and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-YNjqEMFgGy",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code here (load the model from \"./checkpoint.pth\")\n",
    "# Please use `torch.load(\"checkpoint.pth\", map_location='cpu')`\n",
    "tony_net_loaded = TonyNet(vgg16)\n",
    "tony_net_loaded.load_state_dict(torch.load('checkpoint.pth', map_location='cpu'))\n",
    "tony_net_loaded.to(device)\n",
    "tony_net_loaded.eval()\n",
    "correct, total = 0, 0\n",
    "for j, (images, labels) in enumerate(tqdm(test_dataloader)):\n",
    "    with torch.no_grad():\n",
    "        probs = tony_net_loaded(images.to(device))\n",
    "        labels = labels.to(device)\n",
    "        predictions = probs.max(1)[1]\n",
    "        total += len(labels)\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        val_loss = criterion(probs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VYKCk2rnFgG2"
   },
   "outputs": [],
   "source": [
    "val_accuracy = 100 * correct / total # Your code here\n",
    "assert 0 <= val_accuracy <= 100\n",
    "print(\"Validation accuracy: %.2f%%\" % val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy scores (test is above train)\n",
    "![Accuracy](https://drive.google.com/uc?id=1_-hWsllmYH6hH6zAMnlV3KeoaIe5MFuI)\n",
    "### Losses (test is below train)\n",
    "![Loss](https://drive.google.com/uc?id=1RQzzDWJgW3LTAAiWM9IrSsiax4czoZMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "crMQ_SvcFgG7"
   },
   "source": [
    "# Report\n",
    "\n",
    "Below, please mention:\n",
    "\n",
    "* A brief history of tweaks and improvements.\n",
    "* Which network architectures have you tried? What is the final one and why?\n",
    "* What is the training method (batch size, optimization algorithm, number of iterations, ...) and why?\n",
    "* Which techniques have you tried to prevent overfitting? What were their effects? Which of them worked well?\n",
    "* Any other insights you learned.\n",
    "\n",
    "For example, start with:\n",
    "\n",
    "\"I have analyzed these and those conference papers/sources/blog posts. \\\n",
    "I tried this and that to adapt them to my problem. \\\n",
    "The conclusions this task taught me are ...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having knowledge from lectures and having done some googling I decided that I have three main ways to try: ResNet-like architectures, DenseNet (actually, improvement of ResNet in a sense) and VGG-like architectures. From the coursemates I've heard a lot of their result with model with residual connections and many achieve good accuracy scores (~30%) within several epochs (like 10 or even less), but I was more interested to train something similar to VGG, because it was not interesting enough for me to do the same as others do.\n",
    "\n",
    "Firstly I've tried just to download the model and try to train it as is (only changing the last FC layer, because we have different number of classes here), but I quickly stopped attemts. The main reason was that an epoch took like 100+ seconds on GPU and accuracy didn't change much. Actually, it not only didn't change, but it also stayed near $1 / 200$, which means random predictions and absence of learning. So I've built a model TonyNet, in which I took first 16 layers of `features` part of VGG16 and trained it. The motivation was to keep the structure of architecture of the model (that is known to perform good on ImageNet), but slightly reduce the number of parameters to quicken the learning procedure. From the very first moment I used several augmentation techniques like random croppin, horizontal flips, rotation and color jittering and Adam optimizer, because I knew the learning procedure will take long (mostly because of the skip connections absence) and I won't be able to perform all experiment inserting one trick at a time. After several attempts I was still having a random prediction, so I decided to get rid of weight decay (I used it from the beggining to avoid possible overfit). Finally I've managed to find a learning rate (appears that was the initalial problem) that actually made accuracy increase. Funny but `1e-3` is a LR wich doesn't make model to learn at all, but `1e-4` does the job. After several expreiments I've chosen LR in between that still gave some results. The I had an idea that 16 layers of convolutions and poolings will be not enough, so I took 24 first layers of VGG and left others as is (of course tuning first and last FC layers dimentions accordingly).\n",
    "\n",
    "A took a batchsize of 512. Just because. What kind of reasons should I have?.. It must fit GPU and must not be too small not to have many gradient oscillations. I've optimized with Adam, because it's like a standard optimization algorithm (read \"most popular\"). Maybe RMSProp is like a close decision. About the number of iterations... I did the training once for 200 epochs, but the model didn't overfit and continued to learn, so I decided to have 400 and finally reached plateau.\n",
    "\n",
    "As for the overfitting, I didn't need to handle it explicitly, because I didn't see it :). Actully, it has several reasons: I used data augmentation (that's why train score is always lower than test one) and I used dropouts from VGG, which also negates overfitting.\n",
    "\n",
    "P.S. in the task statement it is said to refer papers or blogs. As it was said in the beginning, I was mainly conducted by the lectures materials and some random googling of tiny ImageNet best performing arcitectures, so I don't see the need to refer something here. \n",
    "\n",
    "P.P.S ah, yeah, and you can see that I've tried to use scheduller to reduce learning rate. I even left a model to train during the night with scheduller, but it didn't learn anything and stayed on random predictions :c. I just didn't have time to cook scheduller properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Part 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
